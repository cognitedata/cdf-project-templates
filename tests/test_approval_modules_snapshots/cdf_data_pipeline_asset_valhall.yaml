DataSet:
- description: Asset data for oid
  externalId: ds_asset_oid
  metadata:
    consoleSource: '{"names": ["workmate"]}'
    rawTables: '[{"databaseName": "asset_oid_workmate", "tableName": "assets"}]'
    transformations: '[{"externalId": "tr_asset_oid_workmate_asset_hierarchy", "type":
      "Transformations"}]'
  name: asset:oid
ExtractionPipeline:
- dataSetId: 42
  description: Asset source extraction pipeline with configuration for DB extractor
    reading data from oid:workmate
  documentation: "The DB Extractor is a general database extractor that connects to\
    \ a database, executes one or several queries and sends the result to CDF RAW.\n\
    \nThe extractor connects to a database over ODBC, which means that you need an\
    \ ODBC driver for your database. If you are running the Docker version of the\
    \ extractor, ODBC drivers for MySQL, MS SQL, PostgreSql and Oracle DB are preinstalled\
    \ in the image. See the example config for details on connection strings for these.\
    \ If you are running the Windows exe version of the extractor, you must provide\
    \ an ODBC driver yourself. These are typically provided by the database vendor.\n\
    \nFurther documentation is available [here](./docs/documentation.md)\n\nFor information\
    \ on development, consider the following guides:\n\n * [Development guide](guides/development.md)\n\
    \ * [Release guide](guides/release.md)"
  externalId: ep_src_asset_oid_workmate
  name: src:asset:oid:workmate
  rawTables:
  - dbName: asset_oid_workmate
    tableName: assets
  source: workmate
ExtractionPipelineConfig:
- config: "databases:\n-   connection-string: DSN={MyPostgresDsn}\n    name: postgres\n\
    \    type: odbc\nlogger:\n    console:\n        level: INFO\n    file:\n     \
    \   level: INFO\n        path: file.log\nqueries:\n-   database: postgres\n  \
    \  destination:\n        database: db-extractor\n        table: postgres\n   \
    \     type: raw\n    incremental-field: id\n    initial-start: 0\n    name: test-postgres\n\
    \    primary-key: '{id}'\n    query: \"SELECT\\n\\n  *\\nFROM\\n\\n  mytable\\\
    nWHERE\\n\\n  {incremental_field} >= '{start_at}'\\n\\\n        ORDER BY\\n\\\
    n  {incremental_field} ASC\\n\"\n"
  description: DB extractor config reading data from oid:workmate
  externalId: ep_src_asset_oid_workmate
Group:
- capabilities:
  - rawAcl:
      actions:
      - READ
      - WRITE
      scope:
        tableScope:
          dbsToTables:
            asset_oid_workmate:
              tables: []
  - extractionConfigsAcl:
      actions:
      - READ
      scope:
        extractionPipelineScope:
          ids:
          - 1
  metadata:
    origin: cdf-project-templates
  name: gp_asset_oid_extractor
  sourceId: <change_me>
- capabilities:
  - transformationsAcl:
      actions:
      - READ
      - WRITE
      scope:
        all: {}
  - sessionsAcl:
      actions:
      - LIST
      - CREATE
      - DELETE
      scope:
        all: {}
  metadata:
    origin: cdf-project-templates
  name: gp_asset_oid_processing
  sourceId: <change_me>
- capabilities:
  - rawAcl:
      actions:
      - READ
      - WRITE
      scope:
        tableScope:
          dbsToTables:
            asset_oid_workmate:
              tables: []
  - transformationsAcl:
      actions:
      - READ
      - WRITE
      scope:
        all: {}
  - sessionsAcl:
      actions:
      - LIST
      - CREATE
      - DELETE
      scope:
        all: {}
  - assetsAcl:
      actions:
      - READ
      - WRITE
      scope:
        datasetScope:
          ids:
          - 42
  metadata:
    origin: cdf-project-templates
  name: gp_asset_oid_processing
  sourceId: <change_me>
- capabilities:
  - assetsAcl:
      actions:
      - READ
      scope:
        datasetScope:
          ids:
          - 42
  metadata:
    origin: cdf-project-templates
  name: gp_asset_oid_read
  sourceId: <change_me>
Transformation:
- conflictMode: upsert
  dataSetId: 42
  destination:
    type: asset_hierarchy
  destinationOidcCredentials:
    audience: ${IDP_AUDIENCE}
    cdfProjectName: ${CDF_PROJECT}
    clientId: ${IDP_CLIENT_ID}
    clientSecret: ${IDP_CLIENT_SECRET}
    scopes: ${IDP_SCOPES}
    tokenUri: ${IDP_TOKEN_URL}
  externalId: tr_asset_oid_workmate_asset_hierarchy
  ignoreNullFields: true
  isPublic: true
  name: asset:oid:workmate:asset_hierarchy
  ownerIsCurrentUser: true
  query: "--\n-- Create Asset Hierarchy using Transformation\n--\n-- Input data from\
    \ RAW DB table (using example data)\n--\n-- Root node has parentExternal id =\
    \ ''\n-- Transformation is connected to asset data set\n-- All metadata expect\
    \ selected fileds are added to metadata\n--\nSELECT \n  sourceDb || ':' || tag\
    \          as externalId,\n  if(parentTag is null, \n     '', \n     sourceDb\
    \ || ':' ||parentTag) as parentExternalId,\n  tag                            \
    \ as name,\n  sourceDb                        as source,\n  description,\n  dataset_id('ds_asset_oid')\
    \     as dataSetId,\n  to_metadata_except(\n    array(\"sourceDb\", \"parentTag\"\
    , \"description\"), *) \n                                  as metadata\nFROM \n\
    \  `asset_oid_workmate`.`assets`\n"
  sourceOidcCredentials:
    audience: ${IDP_AUDIENCE}
    cdfProjectName: ${CDF_PROJECT}
    clientId: ${IDP_CLIENT_ID}
    clientSecret: ${IDP_CLIENT_SECRET}
    scopes: ${IDP_SCOPES}
    tokenUri: ${IDP_TOKEN_URL}
TransformationSchedule:
- externalId: tr_asset_oid_workmate_asset_hierarchy
  interval: 7 * * * *
  isPaused: true
deleted:
  ExtractionPipeline:
  - externalId: ep_src_asset_oid_workmate
  Transformation:
  - externalId: tr_asset_oid_workmate_asset_hierarchy
  TransformationSchedule:
  - externalId: tr_asset_oid_workmate_asset_hierarchy
